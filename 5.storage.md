# 5.1 Cinder

# 5.2 Ceph

# 延伸阅读1

目前比较主流的分布式存储（包括Ceph）主打的宣传亮点基本上包含了：<br>
- 算力+性能加速（AI等），确保单节点的性能（比如16.8万IOPS@1ms稳定时延）
- 存储服务合一（比如： 块，文件，对象，HDFS四合一）
- 云协同，全生命周期管理等


## 云和AI时代，数据迎来海量增长
数据增长量，2018年全球32.5ZB, GIV展望，2025年间达到180ZB：
- 5G带来可预期的数据10倍增长
- 8K视频10TB/小时，相比1080P增长了40倍
- 自动驾驶每车每天产生的数据量是60TB
- 某银行大数据精准营销，用户日志年增量PB级

## 企业不断扩展业务边界，分布式架构成为首选

业务需求来源不断扩大：
- 云化整合：<br>
云场景存储资源整合，快速应对不可预知的业务变化
- 海量扩展：<br>
非结构化数据快速增长，需要更高可靠性、更高性能的存储
- 更低的TCO：<br>
高效冗余和数据缩减算法，降低海量数据存储TCO

存储空间变化趋势明显：
从2015年到2021年，分布式，全闪存份额增长趋势明显；

1. 在过去，企业业务单一，少量的存储设备、单一的存储类型即可满足需求
2. 随着企业不断拓展业务边界，有越来越多的云化整合、海量扩展和降TCO的需求，分布式存储成为首选
3. 根据IDC和XXMI的分析显示，存储市场空间正发生着变化，分布式和全闪存将成为主流


## 运营商：建设统一平台，加速多域融合，实现降本增效

统一的平台来支撑三域应用及B2B应用：
- B域应用：CRM，BOSS，经验分析，精准营销；
- M域应用：ERP，财务，人力，资产管理等；
- O域应用：资源管理，业务编排，安全管控，资产管理
- B2B：计算服务，存储服务，网络服务，灾备；

来自中移动的关键需求：
- 弹性扩容<br>
单套存储百PB、按需灵活扩容
- 高性能<br>
百万IOPS，性能随容量线性增长
- 高可用<br>
支撑关键业务7x24h不间断运行
- 低TCO<br>
统一运维管理，无需数据迁移

## 金融：核心系统闪存化，外围业务全面分布式化
来自招行的关键需求
- 弹性部署：按需小时级部署，快速应对突发业务浪涌，降低新业务TTM
- 大集群：单套存储百PB、承载多个业务系统
- 海量扩展：千亿级小对象存储能力，应对电子票据需求
- 低TCO：大数据存算分离，通过解耦实现大数据云化、打通多平台数据孤岛

金融行业常见的业务架构

前端： 渠道接入系统  <->  前置系统 <->  产品服务（核心系统，生产管理系统，CRM系统） <-> 电子影像平台

平台层：数据集成平台（交换平台） <-> 大数据分析平台

内部： 开发测试，办公OA等

## 各行各业以分布式存储为基座推进云战略，加速数字化转型

1. 运营商<br>
5G带来10倍连接及业务多样化预期，持续推进IT系统集中化和业务云化
- 日志留存和竞分大数据
- B2B/B2C内容存储
- BOM域云化
2. 安平<br>
通过大数据、AI实现跨地域、多警种的数据融合和业务协同，提升预测、预警、预防能力
- 离线分析/实时检索大数据
- 非结构化原始库/归档
- 警务云平台
3. 金融<br>
移动互联业务量超过传统业务，精准营销实现千人千面，云、大数据带来数据的海量增长
- 渠道接入
- 票据影像/双录
- 离线大数据分析
4. 大企业<br>
工业4.0，无人驾驶、车联网、4K/8K高清等新产业驱动数据海量增长
- 制造/HPC/媒资/科研文件存储
- 行业云

## 企业云化转型最佳数据底座 - 分布式存储
极致能力：
- 极速体验：<br>
首个支持企业关键应用的分布式存储 （最高性能分布式存储450万IOPS@0.787ms, 企业应用环境中验证，满足易用性、性能和可靠性要求）
- 极致效率：<br>
领先的数据冗余和缩减算法大幅节省TCO
- 智能管理：<br>
基于AI的全生命周期智能管理提升管理效率

## 专用硬件

1. 更高性能， 同等功耗，性能相比x86高15%+
- 绑核机制，提升20%
- 多种算法卸载至ARM，性能提升10%
- FlashLink 0.5ms超低时延
2. 更高可靠性， 完整的硬件故障检测和隔离
- DIF据完整性保护
- 全面亚健康检测：网络/存储/计算/进程
- 精细化IO性能统计
3. 更好兼容性， 一体化部署和交付
- 更清晰故障定界
- 器件质量保障，严格的来料控制和测试

## 商业模式（可用容量，所买即所得）
传统商业模式，硬件统一，软件按照裸容量采购；这种模式下，客户明显吃亏和不平衡： 各个厂商软件能力参差不齐，硬件配置一致，但是客户实际使用的可得容量差距很大；

可用容量（或者可得容量）模式，以实际业务需求为出发点进行采购。有点很明显：
- 相同数据需求下，更少设备，更低采购和维护成本；
- 统一语言，业务，IT和采购部门统一语言，业务需求直接作为采购需求
业务部门： 我需要XPB的可得容量
IT部门：我需要XPB的可得容量
采购部门： 我需要XPB的可得容量
-> 各个厂商参考的招标依据一样，竞争力差异就体现出来了；

## 性能与高端存储媲美
XXEC特点：
1. 磁盘利用率更高：块EC利用率可高达80%；对象、文件EC磁盘空间利用率可高达90%；（VSAN最高只有75%理论）
2. 配置更灵活：N+M冗余比灵活配置，客户可根据不同的业务诉求配置不同的冗余策略。（块：3+1，3+2，4+2，8+2，12+3；文件对象更多，详见冗余配比表。VSAN只支持3+1和4+2）
3. 性能表现更优越：基于小IO场景下SSD Cache做EC条件缓存技术，块存储开启EC场景下，时延表现优于VSAN 40%。
4. 场景更广：支持HDD与SSD介质场景。（VSAN仅能在SSD场景下使用。）

450万IOPS@0.787ms稳定时延, 交易型数据库大压力时性能无波动

## 智能CPU分区算法，时延缩短20%

1. CPU分组算法<br>
IO分组避免相互干扰

- 专核专用，保障关键业务资源投入，降低时延
- 多核共用，自适应调配多个业务的负载均衡

2. CPU分核算法<br>
IO连续执行避免切换消耗

一次请求在同一个核上连续执行，利用同核不发生线程切换从而保证操作原子性来实现免锁设计，避免频繁多核切换，提升CPU Cache命中率

3. IO智能调度
I/O优先级保障，降低业务影响

数据读写I/O永远第一优先级响应，其他I/O等数据读写I/O完成后再重新启动，保障数据读写I/O时延最低

综合上述算法：可达0.5ms 稳定低时延，关键业务极速响应

详情解读

数据从I/O卡流入CPU。XX分布式存储的CPU利用算法具备三大显著优势：
1. CPU采用最新的智能分区算法，包括CPU分组算法和CPU分核算法。CPU分组算法是把比较重要的I/O单独一个分组（比如：读写，数据交换），从而读写I/O与其他I/O部署在不同分组，避免相互干扰，保障读写I/O的性能；优先级相对低的I/O在一个分组内，共享CPU资源。这样能够保障资源利用的最大化。
2. .CPU分核算法是XX独有的优势。我们知道，I/O工作在CPU的时间片是轮询的，一段时间在CPU的Core1上工作，过一段时间轮询到Core2上工作，其一，从Core1跳转到Core2是要花时间的。
其二，为了保障数据的一致性，I/O从core1跳转到core2时，CPU core1会加锁，保证I/O不会在Core1上运行，只在core2上运行，给I/O加锁也是需要时间的。当I/O在core2 上工作一段时间，如果他要跳转回Core1，他需要为Core2加锁，同时为Core1解锁，此时加锁和解锁都是需要时间的。

CPU分核算法，能很好解决CPU轮询和加/解锁的问题，它让1次读请求或者写请求就在CPU的1个core上连续执行，更为重要的是，它采用了免锁设计，这样一个I/O就在一个core上运行，从开始到结束，有效避免了多个Core之间切换，以及加锁、解锁之间的时间消耗。

数据从CPU进入缓存。

缓存对存储而言是非常重要的，缓存算法的优劣是决定存储性能的关键要素之一，缓存算法具备三大亮点：
1. 摒弃传统存储的二叉树算法，采用闪存专用的哈希表算法。众所周知，二叉树算法的空间占用少，但是查找速度慢；哈希表算法查找速度快，空间占用高，采用多级哈希即满足空间占用同时满足高效查找速度
2. 元数据和数据缓存资源分区提升元元数据命中率，读数据和写数据缓存分区避免读写缓存资源互抢；
3. 哈希索引支持冷热分区机制，提升查找速度

## 智能Cache优化算法提升Cache效率，时延波动率低于2%

1. 智能缓存分区<br>
三个区： 元数据区， 写数据区， 热点读数据区
- 元数据长期驻留内存，采用智能淘汰算法优先淘汰冷数据，提升缓存元数据命中率
- 独立缓存空间存放顺序读I/O，空间大小基于业务模型智能调整
- 智能预取算法提前获取热点数据，缩减访问时延

2. 智能分区索引表<br>
分热表，温表，冷表；
- 根据数据访问的冷热频率分成3张分区索引表，提升数据查询速度

## 智能识别数据类型和IO大小，提升效率
大IO和小IO做智能识别。
1. 智能IO聚合与满分条写<br>
- 大IO直接组EC分条下盘，不过Cache，节省Cache资源并提高缓存寿命
- 小IO基于WAL追加写技术，聚合成满分条EC下盘，降低写放大
- 将不同LUN的随机小IO写聚合成100%顺序写，提升性能

2. 元数据和数据独立分区存储<br>
元数据和数据分区存放，元数据采用LSM Tree的Merge方式，数据通过Plog的GC方式，实现垃圾空间回收，降低系统写放大

## 支持NVMe全闪存架构，提供更高品质的服务
NVMe架构缩短端到端时延 45%
- CPU和SSD直接通信，缩短传输路径（SAS全闪存，该段时延可达562微秒， NVMe全闪存该段时延可达314微秒）
- 并发数提升10倍，性能更优
- 协议交互从4次减少为2次，写请求处理效率提升1倍

1. 率先在分布式存储支持NVMe架构：领先于VSAN、CEPH
2. 支持独立NVMe形态，同时支持NVMe和SAS/SATA混插形态：助力用户向NVMe全闪存时代平滑演进

## 垮集群AA双活，支持关键业务数据库的高可用
可以把传统高端存储领域的HyperMetro双活能力，平滑移植到了分布式存储中，实现跨地域的A-A双活，支撑企业关键业务7*24小时稳定运行。
1. 利用独有Fastwrite技术，在同等组网下，时延降低50%
2. “RDMA+”算法优化，实现IP网络百公里业界最低时延

特点：
1. 大规模：全分布式A-A 双活
2. 仲裁模式：第三方仲裁服务器，静态优先级

## 弹性EC，提升磁盘利用率

原始存储一份，三分副本，同时提供弹性EC（包含校验和数据）的方案，支持
1. 全闪或者混合
2. 支持最大配比22+2，或者20+4
3. 最大可容忍4节点故障；

同等硬件配置，有效磁盘使用率可达91%， EC性能相同可靠性副本不降

支持副本和EC冗余机制：
- 机柜级冗余：最大容忍4个机柜同时失效
- 节点级冗余：最大容忍4个节点同时失效
- 硬盘及冗余：最大容忍4个硬盘同时失效

分布式存储提供多副本和纠删码（EC, Erasure code）两种数据冗余保护方式。
多副本方式：支持2副本或3副本，保障硬盘级、节点级、机柜级冗余，最大可支持2机柜同时故障情况下业务不中断。
EC方式：支持3+1，2+2，3+2，3+2(:1)，4+2，4+2(:1) ，8+2，8+2(:1) ，12+3，12+3(:1) 等9种冗余配比，最大可支持3节点同时失效情况下业务不中断。
交底：当+1或+2冗余时，冗余效果不受就否打开EC cache影响；当+3冗余且打开EC cache时，最大容忍2节点或3机柜同时失效；当+3冗余且关闭EC cache时，最大容忍3节点或3机柜同时失效。

## 设备级可靠: 最全面的亚健康智能检测与预处理，提前排除故障风险

亚健康检查和处理

亚健康： 指系统资源性能降级的情况，可能导致业务系统变慢甚至终端

主要涉及：
- 硬盘， 包含故障，慢盘，坏块，Smart信息，UNC错误等
- SSD卡， 包含故障，慢卡， 坏块，高温故障，电容失效，读写次数超过亚健康阈值
- 服务器，包含CPU资源耗尽，CPU频率降低等
- 网络，包含网卡失效，降速，链路丢包，降速，端口故障，闪断，丢包等

详情：

分布式存储XX支持硬盘Smart检测、快慢盘检测、磁盘SCSI错误处理、硬盘热插拔和识别处理、磁盘扫描等，上层业务根据Smart Data返回的相关IO错误和磁盘状态信息， 完成读修复、磁盘移除和重建、坏块标记、有效数据磁盘扫描、Smart超阈值和慢盘处理（预重建后移除磁盘）。

读修复功能（Read  Repair）

Read Repair是一种在读操作时，当发现有读失败，会判断错误类型，如果发现是磁盘扇区读取错误，可以通过从其它副本读取数据，然后重新写入的方法进行恢复。这是磁盘的特性，对大部分读扇区错误可以修复。如果此方法还不能修复，那么就通过隔离流程为副本选择其它硬盘并把故障的硬盘踢出集群。

硬盘：UNC错误是“校验错误”的意思
SSD卡：11000≤磨损度认为处于亚健康状态
服务器：CPU资源耗尽或频率降低，体现在CPU变慢，内存故障，最终体现为节点因服务器部件故障而变慢。
网络：网络丢包、错包，亚健康阈值为4%。1分钟内4次超过阈值则认为处于亚健康状态。网口故障立即出发亚健康。端口闪断1分钟6次、连续3分钟有闪断，则认为处于亚健康。网卡降速立即出发亚健康。链路丢包：60s内30个包丢失2个则认为亚健康。

## IO级可靠：端到端DIF一致性校验，保障数据完整性

1. 数据写入前： 插入校验位,
2. 数据落盘时： 检查校验位
3. 数据读出时： 检查校验位

三个大的流程
1. 在线校验<br>
主机侧写入校验位，数据写盘和和主机读出时进行双校验
2. 后台校验<br>
系统负载较低时，后台自动进行周期性校验
3. 无感自愈<br>
损坏数据本地冗余数据修复，或通过双活数据修复


静默错误: Silent Data Corruption, SDC.
此处“0.00000001% ”隐含了2018年7月腾讯云SDC问题导致用户数据丢失的案例，腾讯云宣称其云硬盘服务可提供99.9999999%（9个9）数据可靠性。
而“100%的投入”是说：虽然静默错误发生的概率很低、而DIF功能开发投入巨大，以致于各分布式存储厂商不愿意投入开发DIF功能解决此问题，XX将分布式存储产品性做到极致，提供端到端DIF较验功能，有效避免静默错误问题。

静默数据错误：数据在磁盘的写入、读出、保存过程中，要经过多个部件、多种传输通道和复杂的软件处理，如果数据被破坏，可能会导致数据错误。若错误无法被立即检测出来，而是在后续应用中访问所保存的数据时才发现，叫做静默数据错误。
XX分布式存储 提供端到端DIF（DIF：Data Integrity Field）校验功能，数据写入磁盘前生成校验值，数据从磁盘读取时自动进行CRC校验，校验失败，尝试通过副本修复并上报告警。当发起的静默错误达到一定阈值时，系统自动隔离异常磁盘。

腾讯云运维关闭数据检验功能，导致其用户“前沿数控”数据丢失事件
“前沿数控”是一家创业公司，定位于数控、模具、机械行业，后转型为一站式平台，开发网站、H5、小程序产品。购买了腾讯云服务。
腾讯云“前沿数控”数据丢失事件始末：2018年7月20日由于TX运维人员在进行日常数据“搬迁扩容”操作前，手动关闭“数据校验”功能，导致“前沿数控”网站、小程序、H5无法登陆云服务器，腾讯云答复云硬盘故障正在紧急恢复；7月22日腾讯云官方承认数据彻底丢失无法修复，并于8月7日发表《关于客户前沿数控数据完整性受损的技术复盘》，指出是由于单副本数据错误+数据迁移前关闭校验+立即删除迁移前的数据导致客户数据丢失导致，数据校验的关闭是此次事故的最关键因素。可见，数据检验在专业数据存储系统中的重要性。

## 10秒节点故障快速切换，业务感知最小化
配合智能网卡等部件，可进一步将故障检测通知时间缩短到毫秒级，提升整体切换效率1倍【2020年】

包含：
1. 进程故障检测
2. 快速心跳转发
3. 快速业务接管
4. 快速IO重定向

XX分布式存储使用普通网卡的通用服务器时，切换时间为10秒，H1版本；使用XX定制智能网卡的服务器时，切换时间为5秒，H2版本。
2019年H2时，CEPH XSKY和VSAN的切换能力为15秒-30秒。

故障快速切换技术原理：

进程故障检测通知，部署监控进程毫秒级监控进程故障后立即拉起进程并通知控制主，控制主判定为进程故障则触发业务本地恢复。
心跳检测机制，针对网络/节点等故障场景导致控制主和业务进程同时失联时，采用“心跳群发+关联诊断”算法在控制新主上快速判定业务进程失联/故障。

快速倒换接管，将需要接管的业务并发倒换到剩余的多节点上，一方面缩短接管时长，一方面使接管后性能更均衡。同时倒换流程使用延迟加载、并行加载、加载数据量缩减、索引快速重建等技术来加速接管过程。

主机IO重定向，VBS层毫秒级检测发往某节点/进程的IO是否返回，如无返回则主动拉取该节点/进程状态视图，如状态视图标示该节点/进程故障则主动断开与该节点网络连接并将IO重定向到新节点/进程。

##  QoS优化：混合负载性能激增场景，实现关键业务性能的智能服务

1. 灵活的QOS调速策略：按盘限制IOPS 带宽；按容量限制IOPS 带宽 ；
2. 灵活的QOS配置策略：可以按照存储池配置QOS策略，也可以按照单个盘设置；
20000是每个卷的最大值？
3000是限死的吗？是否可以针对不同的卷设不同的burst值？
持续时间可调吗

规格及约束：
- QoS策略最大支持64万个；
- 卷的QoS策略高于池的；
- 不支持卷组/共享卷；
- 一个卷或池不能关联多个QoS；
- 删除QoS前，需要先解关联卷或池；
- 卷迁移后，QoS策略不会继承；
- 快照不会继承原卷的QoS；

令牌桶算法：

令牌桶中存放着令牌，只有拿到令牌的IO数据包才能通过，否则会被加入到等待队列中，等待下次调度；

令牌桶分C桶和E桶，C桶大小为Burst的大小，E桶大小为(Burst – 上限) * Burst时长；

使用Burst时，令牌持续从E桶借出到C桶，平时则从C桶存入E桶，直至达到E桶上限。

IO处理流程：

消息IO入对应卷的队列后，Target VBS查找对应卷的上限令牌桶；
根据上限令牌桶查找结果，做如下处理：
- 如果该卷存在上限令牌桶，则从上限令牌桶申请一定数量的令牌，如果成功申请到令牌，则该IO到下一个IO处理模块处理，且令牌桶令牌数减少。
- 如果该卷不存在上限令牌桶（即没有设置QoS），则该IO直接到下一个IO处理模块处理。

对于未成功申请到令牌的IO，会加入一个新的等待队列，在下一个100ms往令牌桶填充令牌数时，优先调度这个等待队列的IO，即，保证IO先到先处理的原则。



## 大数据计算存储分离，弹性EC技术实现TCO节省50%

一体化部署：
1. 顶层包含离线分析，日志留存，经营分析
2. 中间层： 大数据组件
3. 底层： 管理节点，计算存储节点，计算存储节点，计算节点N，组成的Hadoop集群

存算分离部署：
1. 顶层包含离线分析，日志留存，经营分析
2. 中间层： 大数据组件
3. 底层分为两大部分： Hadoop计算集群包含管理节点，计算节点；分布式存储大数据存储集群包含存储节点；通过原生HDFS提供为计算提供存储能力

关键客户价值
1. 计算存储分离<br>
按需独立扩展，避免资源浪费
2. 弹性EC<br>
磁盘利用率从33%提升到91%，单位成本容量提升1.75倍
3. 单目录百亿级文件<br>
全局命名空间，无需拆分目录，简单省事
4. 广泛的兼容<br>
兼容XX FusionInsight、Cloudera、HortonWorks等

## 动态重删压缩：数据缩减率可达5:1，节省存储空间
- 全局重删<br>
资源池内所有数据参与重删
- 前后台自适应<br>
基于负载的自适应，减少业务影响
- 多种介质<br>
支持全闪、混合介质

## 存储永新：0数据迁移，0业务中断

传统模式下，存储管理必须要经历： 设备替换+数据迁移
- 时间： 数月
- 高业务中断风险
- 成本： 15K$/TB

采用了软件定义存储之后： 软件滚动更新，数据自动均衡
- 时间： 数小时
- 0业务终端
- 无需专业服务

## 15分钟/TB高速数据重构，比传统存储恢复快20倍
SSD大Cache + 数据并行重建

分布式存储的 块存储中的每个硬盘都保存了多个数据块（Partition），这些数据块的副本按照策略分散在系统中的其他节点。当分布式存储的 块存储检测到硬盘或者节点硬件发生故障时，自动在后台启动数据修复。由于数据块的副本被分散到多个不同的存储节点上，数据修复时，将会在不同的节点上同时启动数据重建，每个节点上只需重建一小部分数据，多个节点并行工作，有效避免单个节点重建大量数据所产生的性能瓶颈，对上层业务的影响做到最小化。

工作流程：数据分片存储—>硬件故障—>故障自动检测—>自动重构副本—>多节点并行恢复。

分布式存储的 块存储支持并行、快速故障处理和重建：
- 数据块（Partition）及其副本分散在整个资源池内，硬盘故障后，可在资源池范围内自动并行重建。
- 数据分布上支持跨服务器，不会因某个服务器故障导致的数据不可访问和不可重建。
- 故障或者扩容时可以自动进行负载均衡，应用无需调整即可获得更大的容量和性能。

## 单桶1000亿文件存储，满足新兴业务海量小对象需求

比较常见的应用场景：
1. 票据影像
- 千亿级别对象，单套百亿级别文件
- 性能：TPS 1000~10000
2. 卡口图片
- 某大城市，2W路交通摄像头，全年图片数1400亿张
3. IoT车联网
- 大对象，带宽>250MB/s
- 小对象，单桶TPS 300~600

## 云上云下协同，全生命周期智能管理，提升管理效率

云上训练为主，本地训练为辅涵盖全生命周期，包含从资源规划，到业务发放，到系统调优，到风险预测，到故障定位；

云上训练： 充分利用2PB+的特征数据，支持1000+场景。

本地训练： 强调增强训练，提升个性化体验；

XX存储叠加AI的能力，采用了独特的云上训练结合本地增量训练，这样在云上利用数据量大的优势形成基线，同时在本地增量训练，结合具体业务提供个性化调优。

基于这种创新，实现智能管理，如资源的规划从被动到可提前60天预测容量，资源发放从复杂的手工操作到基于经验模板一键式发放，性能调优从手动到自学习自调优，故障从被动处理到可以提前14天预测出即将故障的硬盘，以及根据经验库更加快速准确故障定位等。

这样有什么好处呢？ 例如中航信是市场领先的航空运输旅游业信息技术提供商，拥有全球最大的票据结算系统（Billing and Settlement），2018年处理的民航客票达4亿张。在使用XX智能风险预测服务后，通过对运行系统中数千片硬盘状态的实时监测，提前14天预测出硬盘故障，把风险消除在萌芽之中，让业务更加可靠。

XX内部IT自己的数据中心内有超过500PB的数据。其中传统存储架构的100PB数据，需要5名运维人员。而部署分布式存储的400PB的数据，仅需3名运维人员，运维效率相比传统架构提升6倍 。

## 智能风险预测：提前洞悉存储性能、容量走势，简化管理，提升资源利用率

依托XX云AI深度学习，可以做到：
1. 性能容量趋势60天预判（分析潮汐规律，识别性能瓶颈）
2. 一键式资源发放，1000+ 应用模板
3. 个性化调优，100%满足SLA诉求
4. 提前14天发现故障盘
5. 2000+故障模式库，93%问题发现即给出方案


# 延伸阅读2

未来二三十年，人类一定会进入万物感知、万物互联和万物智能的智能社会。万物感知是入口、万物互联是基础、而万物智能是结果

后摩尔定律时代，技术快速发展，智能世界的核心技术正变得越来越清晰；5G、AI和视频三种技术相互促进、相互激发，加速智能世界的到来。视频+AI，当前49% AI行业应用以视频为基础，视频加速了AI在行业的落地；AI+5G，5G提供的大带宽和低时延让AI的算力无所不及；5G+视频，加速超高清视频（4K/8K）普及，催生了更多行业智能化场景

## 智能视频正成为行业智能化升级的关键，但是仍然面临居多挑战（这个观点值得怀疑）

众所周知，没有智能手机，就没有移动互联网。智能手机扮演着几个重要角色，它是用户体验的入口、也是应用的载体，更是人和人联接的纽带；视频在行业智能化中正扮演着类似的角色，人类的信息获得83%来源于视觉，机器视觉同样也是数字世界的眼睛，提供大量的数据输入；有了AI技术的加持，摄像机也正在成为入口、也是应用的最小载体，正成为物物联接、物理世界与智能世界联接的纽带；所以，智能视频就是行业智能化的“智能手机”！

千行百业的智能化有千百种场景，而当前主要基于垂直生态的智能视频解决方案，参与到千行百业的智能化转型仍然面临居多挑战。比如深圳某单位，有9个业务部门、31个业务系统、147个应用模块，各部门之间争相引入各种智能识别系统，最后造成各个系统形成一个个烟囱，各系统的数据也形成了一个个数据孤岛，阻碍了智能的深化；每出现一个新需求就要新建一个烟囱的系统，设备平台不支持，也无法找更多的生态伙伴提供更多的智能算法。另外一个例子是关于深圳新能源汽车车牌的识别，传统的算法都是固化在摄像机一起的，当新能源车牌识别需求出现后，需要人工上站一个一个去升级，3000路交通卡口升级了一个月才完成。通过这些案例都可以看到，封闭的平台和割裂的生态，是智能视频深入千行百业的核心挑战！


## 推动产业发展，重定义智能视频

重定义智能视频技术架构，让设备和算法解耦，构建开放式的平台。前端摄像机软件定义，按需加载，让通用摄像机秒变专用摄像机。后端视频云平台全云架构，多算法融合，可以打通数据孤岛，实现算力、算法、数据和任务协同。
传统摄像机是专机专用，特点是“算法固化+嵌入式系统+CPU通用处理器”。

而XX软件定义摄像机，从“功能机”到“智能机”，特点是：“软件+硬件的生态+开放的操作系统+NPU专业AI芯”。客户可以根据需求场景，灵活选择各种算法，实现各种智能应用。另外在XX下一代架构里面，也会讲硬件模块化设计，预留标准接口，接入其他的传感器，让末端实现真正的全息感知。

传统的视频云平台建设是堆叠模式，人脸是一套系统、车牌是一套系统，相互之间是割裂的；另外视频的接入、存储、解析、转发、检索等各项功能都需要一个盒子，而且只能加载集成过的算法；这样造成一个个数据孤岛，数据处理难以拉通，数据智能不能充分释放。而XX的智能视频云平台，完全基于云化架构设计，最新的vPaaS 2.0，支持通过SDK和API方式加载各种算法，可以实现一周上车，实现多算法直接的协调配合，同时支持多种算法场景，满足各行业各细分场景的智能需求。

智能深入千行百业，算法需求的长尾化个性化效应越来越明显，而当前的点对点、项目型交易、线下集成的方式，类似于智能手机时代的塞班系统时代，没有一个开放的“交易市场”，让使用者和开发者无法有效沟通，压抑了智能化需求。

为了让使用者按需可选，经济使用；让开发者专注需求，快速迭代。XX发布最新**智能视频新生态的算法商城**。基于XX开放的端边云平台，通过HoloSens商城专业的交易平台、完备的开发平台，**重新定义了智能视频的生态模式**。该商城会提供质量严选服务，让使用者随意挑，快速换，放心用，另外针对开发者还提供“**三云（训练云、调试云、开发云）一社区（开发者社区）**”，让开发者便捷上线，商业成功。

阅读理解：

1. 重新定了新的视频生态。

这个很有新意，传统的视频生态是什么样子的？引入了5G和AI之后视频的生态是什么样子的？

2. 摄像头这个领域

从“功能机”到“智能机”，进入了软硬一体的时代，周边配套的智能芯片，软件开发等生态逐步发展起来了；


波分当前有三板斧，成为世界第一；
存储的三板斧在哪？
海外高端市场；

## 存储销售思考
通常需要解决六个问题4w1H
- What: 卖什么？比如华为Dorado V6的全闪存场景
- Why： 卖什么？思考清楚全闪存的客户价值
- When：产品上市节奏
- Where&Who： 产品上市的区域和目标客户
- How： 如何策划产品的上市
### WHAT：Dorado是5G时代运营商数据中心存储的最佳选择

华为新一代全闪存OceanStor Dorado V3/V6就是这样一款全闪存产品，它综合了原生全闪存和改良全闪存的能力，不仅提供业界领先的700万IOPS@0.5ms的极致稳定高性能，也提供了全面的企业级特性。凭借在性能和企业级特性方面的均衡发展，华为全闪存逐步成为数据中心存储的最佳选择。

华为全闪存的典型业务应用场景如下：

1. BSS关键业务数据库，例如：billing、CRM、内部IT ERP的核心数据库业务对性能和可靠性要求极高（如：通常要求3ms以内的时延和99.9999%可靠性保障），使用华为全闪存可以轻松应对性能和可靠性挑战。
2. VSI（服务器虚拟化）和VDI（桌面虚拟化）：启动、升级、病毒集中查杀等性能风暴需要高性能存储应对；此外，这些业务场景下往往存在比较多的冗余数据量，像VDI全量可隆下最高可以超过10:1的数据缩减，可以大幅节约存储空间。

价值主张：
- 重新定义了性能：<br>
2000万IOPS， Flashlink技术，分布式算力，及AI加持。
- 重新定义了可靠性：<br>
控制器最大容忍8坏7，提升冗余度能力，全互联A-A架构及FlashEver（无中断升级）
- 重新定义了数据密度：<br>
容量密度最高，智能重删压缩，缩减率提升20%+， 高密硬件，容量密度提升；

产品家族：
- 入门级： Dorado3000 V6 SAS
- 中端： Dorado5000 V6 NVMe/SAS， Dorado6000 V6 NVMe/SAS
- 高端： Dorado 8000 V6 NVMe/SAS， Dorado18000 V6 NVMe/SAS

特性提升：


| 变化点 | V3 | V6 | 备注 |
| --- | --- | --- | --- |
| 高端A-A | 支持不同LUN映射给不同控制器实现控制器负载均衡 | 支持单个LUN跨引擎内控制器读写，控制器全负载均衡 | OceanStor Dorado V6核心业务跨引擎负载均衡，跨引擎切换能力更强 |
| 高端可靠性 | 仅支持引擎内故障 | 支持单引擎故障，跨引擎7/8控制器故障，业务不中断 | OceanStor Dorado V6可靠性更高 |
| 端到端NVMe | 只支持后端NVMe | 前后端支持NVMe，后端NVMe扩展能力提升 | --- |
| 处理器 | Intel处理器，核数低 | 华为Kunpeng处理器，核数多 | 国外品牌当前核数均有不同层度提高，V6完全超越友商 |
| IO能力 | 3000/5000 2U盘控一体支持4个IO插槽<br>3U盘控分离支持14个IO插槽<br>6U盘控分离 | 3000 2U盘控一体支持6个IO插槽<br>5000/6000 2U盘控一体支持12个IO插槽<br>4U盘控分离支持28个IO插槽 | V6低端 IO比V3提升明显，与国外品牌竞争力增强 |
| 硬盘框 | 普通SAS/NVMe扩展框（25盘位） | 智能Palm NVMe扩展框（36盘位），支持SAS硬盘框 | --- |
| 异构虚拟化 | 不支持 | 支持 | --- |
| NAS特性 | NAS网关支持 | 不支持 | 无需独立NAS网关,下一个版本支持 |

- OceanStor Dorado V6高端可靠性增强明显，全面超越业界友商，加快NA核心系统拓展
- OceanStor Dorado V6硬件能力提升（CPU核数、入门级IO能力，NVMe支持）明显，CPU核数/缓存/实- 配IO接口卡可作为三围，有效提升友商商务
- OceanStor Dorado V6 20200330可支持NAS，主力市场与友商正面PK。

业务场景支持更加丰富，4层不同SLA保障的分层模型:

|  | Tier 0 | Tier 1 | Tier 2 | Tier 3 |
| --- | --- | --- | --- | --- |
| 业务场景 | 核心应用数据库<br> Biling<br>CRM | 通用数据库（ERP，BI）<br>虚拟化（VSI，VDI） | 数字化业务（VAS，Video） | 备份归档（Backup， Archive） |
| 性能诉求 | 5000-20000 IOPS/TB<br> < 1ms | 500-5000 IOPS/TB<br>  1-5ms | 200-500 IOPS/TB<br>  5-10ms | <200 IOPS/TB<br> > 10ms |
| 可靠性诉求 | 99.9999%<br>垮DC保证业务连续性 | 99.999%<br>垮DC保证数据冗余 | 99.999%<br>垮DC保证数据冗余 | 99.9%<br>本地保证数据冗余 |
| 存储 | 高端存储->高端全闪存 | 中端存储->中端全闪存 | 中低端存储/云存储<br>传统存储长尾市场，或者SDS市场 | 中低端存储/云存储<br>传统存储长尾市场，或者SDS市场 |

### WHY：全闪存存储发展迅猛，数据中心将全面闪存化
行业和市场趋势正驱动存储向全闪存演进，主流运营商已启动存储闪存化行动
1. 立足当下： 好用不贵，降低OPEX<br>
传统存储面临性能瓶颈和OPEX挑战，业务性能要求更高的性能，传统存储性能受限；OPEX占比高（运维人力，维保，能耗，空间，占比约60%， CAPEX设备购置占比约40%）

全闪存价格竞争力凸显： 2018年SSD将下降到HDD的1.6倍， SSD盘的制作工艺，规模化，价格降低趋势明显；

2. 面向未来： 10倍性能，为5G做准备<br>
未来5G时代业务压力巨大，经过2018年的组网实验，2019年试商用，2020年将实现规模商用， 数据爆发即将到来；据市场预测，2020年全闪存将承载所有生产业务；

全闪存存储正在引领一场存储介质的换代革命。业务、产品、价格、市场趋势和客户的选择都宣告了数据中心全闪存化时代已经到来：

- 从业务层面来看：5G时代即将到来，中国三大T、DT、Vodafone等TOP运营商均将在2018年开始启动5G组网试验，2019年预商用，2020年实现规模商用，可以说5G时代已近在咫尺。 普遍预计，5G将带来数据处理并发量的10倍增长，以存储处理的日话单量为例，将从4G时代的6亿条/千万用户增长至60亿条/千万用户，只有全闪存的极致高性能和低时延能力才能满足5G时代的10倍业务处理能力要求。

- 从产品层面来看：数据量以每年约30%+的速度增长，存储性能能否随容量线性扩展，提供可预见的容量和性能扩展能力成为考量新建存储系统的关键。受限于存储介质和架构，面对容量的持续增长，机械硬盘带来的传统存储性能瓶颈也越加凸显；此外，传统存储容量密度低，且依赖于通过堆叠大量硬盘来提升性能，这带来了大量的空间占用、能耗、维保等OPEX费用支出，传统存储的OPEX占到整个设备生命周期TCO的约60%，降OPEX的需求强烈。

- 从价格层面来看：随着全闪存的不断发展和成熟，全闪存存储单位价格将持续下降，并于2018年底SSD每GB的价格将下降到HDD的2倍，这大大提升了全闪存成本方面的竞争力。

- 从市场层面来看：从市场选择来看，业内预测在2017年已出现拐点，全闪存存储的市场份额在17年超过传统存储，在2020年，所有的生产业务都会部署全闪存。

- 从客户选择层面来看：主流运营商已积极拥抱闪存化趋势，启动存储闪存化行动，例如：TI、KPN、DT、Telefonica、MTN、SFR、Proximus、Hi3G、PLDT、Claro等。

TCO、数据迁移、重删压缩保证期

华为在闪存领域已有超过12年的持续积累。华为全闪存的关键在于业界独有的端到端芯片上的自研创新：
- SSD控制芯片：将SSD核心的算法从系统软件装载到芯片中，优化SSD盘的数据读写，时延仅为友商的60%，实测性能业界最高，同时SSD寿命提升20%；
- 多协议接口芯片：将8G/16G FC/10GE/FCoE等连接主机接口的网络协议卸载在一张卡内，按需适配；协议硬件卸载，性能提升3倍；
- 智能管理芯片：对设备和部件进行精细化监控和管理，芯片计算能力提升5倍，冗余部件故障时实现秒级切换

依托芯片创新，华为也成为业内唯一能同时自研存储操作系统、控制器、SSD盘、SSD控制芯片的厂商。因此，华为能打造出业内最快最稳的全闪存存储：
- 业界最高性能：基于业界独家的盘控配合技术FLASHLINKTM，华为全闪存存储可提供极致稳定性能（补充信息：2018年在MWC上发布的Dorado18000高端全闪存产品树立了存储性能新标杆：700万IOPS，0.5ms时延）。在实验室对比测试中，华为全闪存存储性能全面领先同类友商产品；
- 业界最高可靠性：
最高系统级数据可靠性：华为允许系统中三个盘同时故障的情况下业务不中断，数据不丢失。市场上主流的厂商包括DELL EMC和HP，都只支持2块盘同时失效；此外，华为可实现30分钟/TB的数据快速重构，这比友商快10X。
- 最高方案级业务可靠性：华为基于业界领先的免网关双活方案，确保业务24/7不间断运行，以业界最具性价比的双活方案实现99.9999%最佳业务可靠性。

此外，基于华为近30年服务于全球电信客户所积累起来的本地化服务能力，华为能快速响应客户服务需求，根据用户实际业务系统和应用特点提供量身定制的数据迁移方案，以全球上千个迁移项目交付经验保证客户数据安全和业务连续性；

以意大利电信全闪存项目交付为例，其中涉及150+业务应用，共计3PB+的数据迁移。华为为客户提供专业的数据迁移服务，计划分4个阶段、共历时2.5年将数据从EMC\HDS/HP/IBM等厂商的传统存储迁移至华为全闪存存储上。当前已完成前3期的数据迁移任务，整个迁移过程零事故，获得客户高度认可，并主动邀请华为帮助其分析现网其他即将过保存储的整合替换和迁移方案。

端到端自研创新的存储芯片、业界最佳的全闪存产品、快速响应的本地化专业服务三大核心优势让华为成为闪存领域发展最为迅猛的厂商。据IDC最新的咨询报告显示，2017年华为全闪存存储市场收入增速位列全球第一。在运营商领域，华为新一代全闪存存储Dorado V3自上市以来，在不到一年的时间里迅速赢得全球40+主流运营商的信赖（如：TI、KPN、DT、Telefonica、MTN、SFR、Proximus、Hi3G、PLDT等），并逐步成为全球更多运营商客户数据中心存储的最佳选择。

华为Dorado存储价值主张
1. 主题： 永快永稳“芯”存储
2. 价值主张： 新一代智能全闪存标杆，以快制胜，以智应变，行稳致远
3. 客户痛点<br>
- 数据规模变大，增加数据挖掘难度——数据集中化
- 7*24 连续运行+更快响应是业务实时化的基本要求——应用实时化
- 有限资源难以解决大量业务带来的管理问题——运维智能化
4. 关键信息
- 重新定义性能<br>
No.1性能，超友商2倍，芯片构建端到端极速平台，实现2000万IOPS，0.1ms时延的极致性能
  - 高性能鲲鹏920芯片：SPECint benchmark第一(930分+ )，超越业界主流CPU 25%
  - NVMe全互联+AI Fabric无损网络：端到端NVMe高速协议配合iLosslessTM智能无损算法，时延降低30%
  - AI加速芯片+智能缓存算法：深度学习业务IO规律，读命中率提升50%，存储越用越快
  - 智能高密硬盘框 (18块SSD/U)：内置自研芯片智能分担系统算力，性能与容量双重线性扩展，业界唯一
- 重新定义可靠性<br>
No. 1可靠性的SmartMatrix架构，保障业务永远在线
  - 业务0中断：业界唯一支持控制器单点/双点/多点（8坏7，跨引擎）故障，业务连续运行
  - 故障0感知：控制器故障后1秒切换，主机链路不断，上层业务无感知，体验更优
  - 升级0影响：组件化在线升级(1秒)，主机业务无感知，业界最优（EMC 3-5秒，HDS 10+秒）
- 重新定义管理<br>
AI使能的全生命周期智能管理，数据永不迁移
  - 云上云下协同：云上通用智能+边缘个性化智能，设备内置昇腾A310 AI芯片增量训练，深度学习业务特征，提升个性化体验
  - AI贯穿业务全生命周期：从资源发放到故障定位全方位智能，使得性能容量趋势提前60天预判、系统提前14天发现故障盘、93%问题发现即给出方案
  - FLASHEVER设备永新：智能弹性架构实现模块化升级，数据无需迁移，用户即可持续享用最新一代软硬件能力，保护用户投资

### How： 聚焦三大场景

| 客户痛点 | 典型场景 | 解决方案 | 关键动作 |
| --- | --- | --- | --- |
| 1) 4.5G/5G，计费实时性要求提升<br>2) Billing报表时间长，性能提升<br>3) VDI\VSI启动风暴，用户使用卡顿 | 业务加速场景 | 业务加速 | 技术交流解决认知问题，PoC证明实力 |
| 1) 设备过保，维保成本高<br> 2) 设备老旧，性能及可靠性下降<br> 3) 设备Vendor多，管理效率低 | 老旧OPEX高场景 | 存储整合 | 做好看网讲网，TCO算账体现商业价值（看网讲网，TCO分析，数据迁移） |
| 1) 运营商转型，降本增效<br>2) 采购效率低、议价能力差<br>3) 子网投资对集团不可见不可控 | 成本驱动场景 | 框架采购 | 突破拿门票（短名单突破，子网PoC突破等）（拿门票，引典配，提销毛） |
