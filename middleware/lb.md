# 负载均衡的原理、分类、实现架构，以及使用场景

## 为什么需要负载均衡

当系统面临大量用户访问，负载过高的时候，通常会使用增加服务器数量来进行**横向扩展，使用集群和负载均衡提高整个系统的处理能力**。

从单机网站到分布式网站，很重要的区别是**业务拆分和分布式部署**，将应用拆分后，部署到不同的机器上，实现大规模分布式系统。分布式和业务拆分解决了，从集中到分布的问题，但是**每个部署的独立业务还存在单点的问题和访问统一入口问题**，为**解决单点故障，我们可以采取冗余的方式。将相同的应用部署到多台机器上**。** 解决访问统一入口问题，我们可以在集群前面增加负载均衡设备，实现流量分发**。

## 负载均衡的原理

系统的扩展可分为纵向（垂直）扩展和横向（水平）扩展。
- 纵向扩展<br>
纵向扩展，是从单机的角度通过**增加硬件处理能力**，比如CPU处理能力，内存容量，磁盘等方面，实现服务器处理能力的提升，不能满足大型分布式系统（网站），大流量，高并发，海量数据的问题。

- 横向扩展<br>
因此需要采用横向扩展的方式，通过添加机器来满足大型网站服务的处理能力。比如：一台机器不能满足，则增加两台或者多台机器，共同承担访问压力。这就是典型的集群和负载均衡架构：如下图：

![横向扩展](http://p3.pstatp.com/large/pgc-image/1535196319496c926a43ca4)

- 应用集群：将同一应用部署到多台机器上，组成处理集群，接收负载均衡设备分发的请求，进行处理，并返回相应数据。
- 负载均衡设备：将用户访问的请求，根据负载均衡算法，分发到集群中的一台处理服务器。（一种把网络请求分散到一个服务器集群中的可用服务器上去的设备）

## 负载均衡的作用

1. 解决并发压力，提高应用处理性能（增加吞吐量，加强网络处理能力）；
2. 提供故障转移，实现高可用；
3. 通过添加或减少服务器数量，提供网站伸缩性（扩展性）；
4. 安全防护；（负载均衡设备上做一些过滤，黑白名单等处理）

## 负载均衡的分类

![负载均衡分类](http://p3.pstatp.com/large/pgc-image/15351957983814651d7fac3)

1. 二层负载均衡（mac）

根据OSI模型分的二层负载，一般是用虚拟mac地址方式，外部对虚拟MAC地址请求，负载均衡接收后分配后端实际的MAC地址响应）

2. 三层负载均衡（ip）

一般采用虚拟IP地址方式，外部对虚拟的ip地址请求，负载均衡接收后分配后端实际的IP地址响应）

3. 四层负载均衡（tcp）

在三次负载均衡的基础上，用ip+port接收请求，再转发到对应的机器。

4. 七层负载均衡（http）

根据虚拟的url或IP，主机名接收请求，再转向相应的处理服务器。

## 最常见的四层和七层负载均衡

1. 四层的负载均衡就是基于IP+端口的负载均衡：在三层负载均衡的基础上，通过发布三层的IP地址（VIP），然后加四层的端口号，来决定哪些流量需要做负载均衡。

对应的负载均衡器称为四层交换机（L4 switch），主要分析IP层及TCP/UDP层，实现四层负载均衡。此种负载均衡器不理解应用协议（如HTTP/FTP/MySQL等等）。

实现四层负载均衡的软件有：
- F5：硬件负载均衡器，功能很好，但是成本很高。
- lvs：重量级的四层负载软件
- nginx：轻量级的四层负载软件，带缓存功能，正则表达式较灵活
- haproxy：模拟四层转发，较灵活


2. 七层的负载均衡就是基于虚拟的URL或主机IP的负载均衡

对应的负载均衡器称为七层交换机（L7 switch），除了支持四层负载均衡以外，还有分析应用层的信息，如HTTP协议URI或Cookie信息，实现七层负载均衡。此种负载均衡器能理解应用协议。

实现七层负载均衡的软件有：

- haproxy：天生负载均衡技能，全面支持七层代理，会话保持，标记，路径转移；
- nginx：只在http协议和mail协议上功能比较好，性能与haproxy差不多；
- apache：功能较差
- Mysql proxy：功能尚可。

总的来说，一般是lvs做4层负载；nginx做7层负载；haproxy比较灵活，4层和7层负载均衡都能做。

## 负载均衡应用场景

![负载均衡应用场景](http://p3.pstatp.com/large/pgc-image/1535195951224c86023a139)

### 场景一：应用于高访问量的业务

如果您的应用访问量很高，您可以通过配置监听规则将流量分发到不同的服务器上。

### 场景二：横向扩张系统

您可以根据业务发展的需要，通过随时添加和移除服务器，来扩展应用系统的服务能力，适用于各种Web服务器和App服务器。

### 场景三：消除单点故障

当其中一部分服务器发生故障后，负载均衡会自动屏蔽故障的服务器，将请求分发给正常运行的服务器，保证应用系统仍能正常工作。

### 场景四：同城容灾 （多可用区容灾）

为了提供更加稳定可靠的负载均衡服务，当主可用区出现机房故障或不可用时，负载均衡仍然有能力在非常短的时间内切换到另外一个备可用区恢复服务能力；当主可用区恢复时，负载均衡同样会自动切换到主可用区提供服务，保证服务依然正常运行。

# 负载均衡案例

## 一、 什么是负载均衡？

** 什么是负载均衡？**

记得第一次接触 Nginx 是在实验室，那时候在服务器部署网站需要用 Nginx 。Nginx 是一个服务组件，用来反向代理、负载平衡和 HTTP 缓存等。那么这里的 负载均衡 是什么？

负载均衡（LB，Load Balance），是一种技术解决方案。用来在多个资源（一般是服务器）中分配负载，达到最优化资源使用，避免过载。

![负载均衡示意](http://p1.pstatp.com/large/pgc-image/43f30a80c3ee41fbbc61945361e39694)

资源，相当于每个服务实例的执行操作单元，负载均衡就是将大量的数据处理操作分摊到多个操作单元进行执行，用来解决互联网分布式系统的大流量、高并发和高可用的问题。那什么是高可用呢？

## 二、什么是高可用？
首先了解什么是高可用？

这是 CAP 定理是分布式系统的基础，也是分布式系统的 3 个指标：

1. Consistency（一致性）
2. Availability（可用性）
3. Partition tolerance（分区容错性）

高可用（High Availability）是什么？高可用，简称 HA，是系统一种特征或者指标，通常是指，提供一定性能上的服务运行时间，高于平均正常时间段。反之，消除系统服务不可用的时间。

衡量系统是否满足高可用，就是当一台或者多台服务器宕机的时候，系统整体和服务依然正常可用。

举个例子，一些知名的网站保证 4 个 9 以上的可用性，也就是可用性超过 99.99%。那 0.01% 就是所谓故障时间的百分比。比如电商网站有赞，服务不可用会造成商家损失金钱和用户。那么在提高可用性基础上同时，对系统宕机和服务不可用会有补偿。

比如下单服务，可以使用带有负载均衡的多个下单服务实例，代替单一的下单服务实例，即使用冗余的方式来提高可靠性。

总而言之，负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一。一般通过负载均衡，冗余同一个服务实例的方式，解决分布式系统的大流量、高并发和高可用的问题。** 负载均衡核心关键：在于是否分配均匀 ** 。

## 三、常见的负载均衡案例

![案例](http://p1.pstatp.com/large/pgc-image/324fd6cf12cf4e7584d538c1a3b6a8b5)

### 场景1：微服务架构中，网关路由到具体的服务实例 hello：

- 两个相同的服务实例 hello service ，一个端口 8000 ，另一个端口 8082
通过 Kong 的负载均衡 LB 功能，让请求均匀的分发到两个 hello 服务实例
- Kong 的负载均衡策略算法很多：默认 weighted-round-robin 算法，还有 consumer: consumer id 作为 hash 算法输入值等

![微服务场景负载均衡](http://p1.pstatp.com/large/pgc-image/cefa70de28c74c7184bbb62f2f5a5acb)

### 场景2：微服务架构中，A 服务调用 B 服务的集群。通过了 Ribbon 客户端负载均衡组件：

- 负载均衡策略算法并不高级，最简单的是随机选择和轮循

## 四、互联网分布式系统解决方案

![互联网架构](http://p1.pstatp.com/large/pgc-image/5749fa8bdbcd4eda9983d53767bf3693)
常见的互联网分布式系统架构分为几层，一般如下：

- 客户端层：比如用户浏览器、APP 端
- 反向代理层：技术选型 Nignx 或者 F5 等
- Web 层：前后端分离场景下， Web 端可以用 NodeJS 、 RN 、Vue
- 业务服务层：用 Java 、Go，一般互联网公司，技术方案选型就是 SC 或者 Spring Boot + Dubbo 服务化
- 数据存储层：DB 选型 MySQL ，Cache 选型 Redis ，搜索选型 ES 等

一个请求从第 1 层到第 4 层，层层访问都需要负载均衡。即每个上游调用下游多个业务方的时候，需要均匀调用。这样整体系统来看，就比较负载均衡

### 第 1 层：客户端层 -> 反向代理层 的负载均衡

客户端层 -> 反向代理层的负载均衡如何实现呢？

答案是：DNS 的轮询。 DNS 可以通过 A （Address，返回域名指向的 IP 地址）设置多个 IP 地址。比如这里访问 bysocket.com 的 DNS 配置了 ip1 和 ip2 。为了反向代理层的高可用，至少会有两条 A 记录。这样冗余的两个 ip 对应的 nginx 服务实例，防止单点故障。

每次请求 bysocket.com 域名的时候，通过 DNS 轮询，返回对应的 ip 地址，每个 ip 对应的反向代理层的服务实例，也就是 nginx 的外网ip。这样可以做到每一个反向代理层实例得到的请求分配是均衡的。

### 第 2 层：反向代理层 -> Web 层 的负载均衡

反向代理层 -> Web 层 的负载均衡如何实现呢？

是通过反向代理层的负载均衡模块处理。比如 nginx 有多种均衡方法：

1. 请求轮询。

请求按时间顺序，逐一分配到 web 层服务，然后周而复始。如果 web 层服务 down 掉，自动剔除

```
upstream web-server {
  server ip3;
  server ip4;
}
```
ip 哈希。按照 ip 的哈希值，确定路由到对应的 web 层。只要是用户的 ip 是均匀的，那么请求到 Web 层也是均匀的。

还有个好处就是同一个 ip 的请求会分发到相同的 web 层服务。这样每个用户固定访问一个 web 层服务，可以解决 session 的问题。
```
upstream web-server {
  ip_hash;
  server ip3;
  server ip4;
}
```
weight 权重 、 fair、url_hash 等

### 第 3 层：Web 层 -> 业务服务层 的负载均衡

Web 层 -> 业务服务层 的负载均衡如何实现呢？

比如 Dubbo 是一个服务治理方案，包括服务注册、服务降级、访问控制、动态配置路由规则、权重调节、负载均衡。其中一个特性就是智能负载均衡：内置多种负载均衡策略，智能感知下游节点健康状况，显著减少调用延迟，提高系统吞吐量。

为了避免避免单点故障和支持服务的横向扩容，一个服务通常会部署多个实例，即 Dubbo 集群部署。会将多个服务实例成为一个服务提供方，然后根据配置的随机负载均衡策略，在20个 Provider 中随机选择了一个来调用，假设随机到了第7个 Provider。LoadBalance 组件从提供者地址列表中，使用均衡策略，选择选一个提供者进行调用，如果调用失败，再选另一台调用。

Dubbo内置了4种负载均衡策略:

- RandomLoadBalance:随机负载均衡。随机的选择一个。是Dubbo的默认负载均衡策略。
- RoundRobinLoadBalance:轮询负载均衡。轮询选择一个。
- LeastActiveLoadBalance:最少活跃调用数，相同活跃数的随机。活跃数指调用前后计数差。使慢的 Provider 收到更少请求，因为越慢的 Provider 的调用前后计数差会越大。
- ConsistentHashLoadBalance:一致性哈希负载均衡。相同参数的请求总是落在同一台机器上。

同样，因为业务的需要，也可以实现自己的负载均衡策略

### 第 4 层：业务服务层 -> 数据存储层 的负载均衡

数据存储层的负载均衡，一般通过 DBProxy 实现。比如 MySQL 分库分表。

当单库或者单表访问太大，数据量太大的情况下，需要进行垂直拆分和水平拆分两个维度。比如水平切分规则：

- Range 、 时间
- hash 取模，订单根据店铺ID 等

但伴随着这块的负载会出现下面的问题，需要解决：
- 分布式事务
- 跨库 join 等

现状分库分表的产品方案很多：当当 sharding-jdbc、阿里的 Cobar 等

## 五、小结

对外看来，负载均衡是一个系统或软件的整体。对内看来，层层上下游调用。只要存在调用，就需要考虑负载均衡这个因素。所以负载均衡（Load Balance）是分布式系统架构设计中必须考虑的因素之一。考虑主要是如何让下游接收到的请求是均匀分布的：

- 第 1 层：客户端层 -> 反向代理层 的负载均衡。通过 DNS 轮询
- 第 2 层：反向代理层 -> Web 层 的负载均衡。通过 Nginx 的负载均衡模块
- 第 3 层：Web 层 -> 业务服务层 的负载均衡。通过服务治理框架的负载均衡模块
- 第 4 层：业务服务层 -> 数据存储层 的负载均衡。通过数据的水平分布，数据均匀了，理论上请求也会均匀。比如通过买家ID分片类似

# 负载均衡深探

我们都对高可用有一个基本的认识，其中负载均衡是高可用的核心工作。本文将通过如下几个方面，让你妥妥的吃透“”负载均衡”。

![引子](http://p1.pstatp.com/large/pgc-image/15397488806888dfa30abfb)

- 负载均衡是什么
- 常用负载均衡策略图解
- 常用负载均衡策略优缺点和适用场景
- 用健康探测来保障高可用
- 结语

## 负载均衡是什么

![负载均衡写实](http://p3.pstatp.com/large/pgc-image/1539748880878ab23dd62f5)


正如上图所示的这样，由一个独立的统一入口来收敛流量，再做二次分发的过程就是负载均衡，它的本质和分布式系统一样，是分治。

如果大家习惯了开车的时候用一些导航软件，我们会发现，导航软件的推荐路线方案会有一个数量的上限，比如 3 条、5 条。

因此，其实本质上它也起到了一个类似负载均衡的作用，因为如果只能取 Top3 的通畅路线，自然拥堵严重的路线就无法推荐给你了，使得车流的压力被分摊到了相对空闲的路线上。

在软件系统中也是一样的道理，为了避免流量分摊不均，造成局部节点负载过大(如 CPU 吃紧等)，所以**引入一个独立的统一入口来做类似上面的“导航”的工作**。

但是，软件系统中的负载均衡与导航的不同在于：导航是一个柔性策略，最终还是需要使用者做选择，而前者则不同。

** 怎么均衡的背后是策略在起作用，而策略的背后是由某些算法或者说逻辑来组成的。**

比如，导航中的算法属于路径规划范畴，在这个范畴内又细分为静态路径规划和动态路径规划，并且，在不同的分支下还有各种具体计算的算法实现，如 Dijikstra、A* 等。

同样的，在软件系统中的负载均衡，也有很多算法或者说逻辑在支撑着这些策略，巧的是也有静态和动态之分。

## 常用负载均衡策略图解

下面来罗列一下日常工作中最常见的 5 种策略。

1. 轮询

![轮询](http://p1.pstatp.com/large/pgc-image/15397488807670a0959bd96)

这是最常用也最简单策略，平均分配，人人都有、一人一次。大致的代码如下：

```
int globalIndex = 0; //注意是全局变量，不是局部变量。

try
{

  return servers[globalIndex];
}
finally
{
  globalIndex++;
  if (globalIndex == 3)
  globalIndex = 0;
}
```
2. 加权轮询

![加权轮询](http://p3.pstatp.com/large/pgc-image/1539748880648cc2edeacb7)

在轮询的基础上，增加了一个权重的概念。权重是一个泛化后的概念，可以用任意方式来体现，本质上是一个能者多劳思想。

比如，可以根据宿主的性能差异配置不同的权重。大致的代码如下：

```
int matchedIndex = -1;
int total = 0;

for (int i = 0; i < servers.Length; i++)
{
  servers[i].cur_weight += servers[i].weight;//①每次循环的时候做自增（步长=权重值）
  total += servers[i].weight;//②将每个节点的权重值累加到汇总值中
  if (matchedIndex == -1 || servers[matchedIndex].cur_weight < servers[i].cur_weight) //③如果 当前节点的自增数 > 当前待返回节点的自增数，则覆盖。
  {
    matchedIndex = i;
  }
}
servers[matchedIndex].cur_weight -= total;//④被选取的节点减去②的汇总值，以降低下一次被选举时的初始权重值。
return servers[matchedIndex];
```

这段代码的过程如下图的表格。"()"中的数字就是自增数，即代码中的 cur_weight。

![加权轮询算法](http://p3.pstatp.com/large/pgc-image/1539748880782562fd30602)


值得注意的是，加权轮询本身还有不同的实现方式，虽说最终的比例都是 2：1：2。

但是在请求送达的先后顺序上可以有所不同。比如「5-4，3，2-1」和上面的案例相比，最终比例是一样的，但是效果不同。

「5-4，3，2-1」更容易产生并发问题，导致服务端拥塞，且这个问题随着权重数字越大越严重。

例子：10：5：3 的结果是「18-17-16-15-14-13-12-11-10-9，8-7-6-5-4，3-2-1」

3. 最少连接数

![最少连接数](http://p1.pstatp.com/large/pgc-image/15397488807961267525430)

这是一种根据实时的负载情况，进行动态负载均衡的方式。维护好活动中的连接数量，然后取最小的返回即可。大致的代码如下：

```
var matchedServer = servers.orderBy(e => e.active_conns).first();

matchedServer.active_conns += 1;

return matchedServer;

//在连接关闭时还需对active_conns做减1的动作。
```

4. 最快响应

![最快响应](http://p1.pstatp.com/large/pgc-image/153974888097641ec4ac212)


这也是一种动态负载均衡策略，它的本质是根据每个节点对过去一段时间内的响应情况来分配，响应越快分配的越多。

具体的运作方式也有很多，上图的这种可以理解为，将最近一段时间的请求耗时的平均值记录下来，结合前面的加权轮询来处理，所以等价于 2：1：3 的加权轮询。

题外话：一般来说，同机房下的延迟基本没什么差异，响应时间的差异主要在服务的处理能力上。

如果在跨地域(例：浙江->上海，还是浙江->北京)的一些请求处理中运用，大多数情况会使用定时「Ping」的方式来获取延迟情况，因为是 OSI 的 L3 转发，数据更干净，准确性更高。

5. Hash 法

![Hash 法](http://p1.pstatp.com/large/pgc-image/15397488810613d7b629410)


Hash 法的负载均衡与之前的几种不同在于，它的结果是由客户端决定的。通过客户端带来的某个标识经过一个标准化的散列函数进行打散分摊。上图中的散列函数运用的是最简单粗暴的取余法。

题外话：散列函数除了取余之外，还有诸如**变基、折叠、平方取中**法等等，此处不做展开，有兴趣的小伙伴可自行查阅资料。

另外，被求余的参数其实可以是任意的，只要最终转化成一个整数参与运算即可。

最常用的应该是用来源 IP 地址作为参数，这样可以确保相同的客户端请求尽可能落在同一台服务器上。

## 常用负载均衡策略优缺点和适用场景

我们知道，没有完美的事物，负载均衡策略也是一样。上面列举的这些最常用的策略也有各自的优缺点和适用场景，我稍作了整理，如下。

![对比](http://p1.pstatp.com/large/pgc-image/153974888088380f38329ac)

这些负载均衡算法之所以常用也是因为简单，想要更优的效果，必然就需要更高的复杂度。

比如，可以将简单的策略组合使用、或者通过更多维度的数据采样来综合评估、甚至是基于进行数据挖掘后的预测算法来做。

## 用健康探测来保障高可用

不管是什么样的策略，难免会遇到机器故障或者程序故障的情况。所以要确保负载均衡能更好的起到效果，还需要结合一些健康探测机制。定时的去探测服务端是不是还能连上，响应是不是超出预期的慢。

如果节点属于“不可用”的状态的话，需要将这个节点临时从待选取列表中移除，以提高可用性。一般常用的健康探测方式有 3 种。

1. HTTP 探测

使用 Get/Post 的方式请求服务端的某个固定的 URL，判断返回的内容是否符合预期。一般使用 HTTP 状态码、Response 中的内容来判断。

2. TCP 探测

基于 TCP 的三次握手机制来探测指定的 IP + 端口。最佳实践可以借鉴阿里云的 SLB 机制，如下图：

![阿里云slb](http://p3.pstatp.com/large/pgc-image/15397488808786fdd1c4992)


值得注意的是，为了尽早释放连接，在三次握手结束后立马跟上 RST 来中断 TCP 连接。

3. UDP 探测

可能有部分应用使用的是 UDP 协议。在此协议下可以通过报文来进行探测指定的 IP + 端口。最佳实践同样可以借鉴阿里云的 SLB 机制，如下图：

![阿里云slb](http://p3.pstatp.com/large/pgc-image/1539748880910b3b555d0e0)


结果的判定方式是：在服务端没有返回任何信息的情况下，默认是正常状态。否则会返回一个 ICMP 的报错信息。

## 结语

用一句话来概括负载均衡的本质是：** 将请求或者说流量，以期望的规则分摊到多个操作单元上进行执行**。

通过它可以实现横向扩展(scale out)，将冗余的作用发挥为高可用。另外，还可以物尽其用，提升资源使用率。

# 负载均衡种类

在互联网大行其道的今天，随着业务的迅猛增长，技术上我们常常要面对高并发，大流量。

![序](http://p3.pstatp.com/large/pgc-image/50bc0cb016de4bd9a6b8a10d27afceec)

为了实现高可用，高性能我们采用了很多的技术手段，负载均衡就是其中之一。作为外部流量与内部应用的“接引者”，它占据了重要的地位。

我们是否了解整个负载均衡技术?它的分类?它的原理?它的特点?今天让我们一起来漫谈负载均衡吧。

## 负载均衡的分类

谈到负载均衡，大家都会想到 Nginx，通常我们会用它做应用服务的负载均衡。

一般它的并发量在 5W 左右，如果并发量再高就需要做 Nginx 的集群了。但 Nginx 之上还有一层负载均衡器，是它把网络请求转发给 Nginx 的，同时还会肩负网络链路，防火墙等工作。

它就是**“硬件负载均衡器”** ，一般安装在外部网络与内网服务器之间。比较流行的有 NetScaler，F5，Radware，Array 等产品。

![硬件负载均衡](http://p9.pstatp.com/large/pgc-image/10f86916042d4b7ab50c34f552b3f589)

硬件负载均衡器在外网和内网之间

相对于“硬件负载均衡器”来说，对内网服务器进行负载均衡就属于“软件负载均衡器”。例如：LVS，HAProxy，Nginx。

硬件负载均衡工作在“接入层”，主要任务是多链路负载均衡，防火墙负载均衡，服务器负载均衡。

软件负载均衡工作在“代理层”，主要任务是反向代理，缓存，数据验证等等。

![应用和接入负载均衡](http://p3.pstatp.com/large/pgc-image/c147ce3e3b0a4eea87963bd5acc8a844)

硬件负载均衡和软件负载均衡工作在不同的层

硬件负载均衡在接入层获得网络请求，然后转交给软件负载均衡，用同样的方式处理返回的请求。

![代理层](http://p9.pstatp.com/large/pgc-image/acde680f2aed4e01a0ef22f0416c7c37)

接入层，代理层，应服务器示意图

我们知道了负载均衡分为“硬件负载均衡”和“软件负载均衡”，那么来逐一看看他们是如何工作的吧。

## 硬件负载均衡

既然前面提到了负载均衡器的分类，那么我们就来聊聊他们的特点。硬件负载均衡技术只专注网络判断，不考虑业务系统与应用使用的情况。

看上去它对处理网络请求是非常专业的，但有趣的是，如果应用服务出现了流量瓶颈，而“接入层”的硬件负载均衡没有发现异常，还是让流量继续进入到应用服务器，并没有阻止，就会造成应用服务器流量过大。

所以，为了保证高可用，可以在“接入层”和“代理层”同时考虑限流的问题。

作为硬件负载均衡器，常在大企业使用。下面我们以 F5 公司的“F5 BIG-IP”产品为蓝本给大家介绍(下面简称 F5)。

实际上它是一个集成的解决方案，对于研发的同学来说，主要理解其原理。

### 硬件负载均衡器三大功能

上面谈到硬件负载均衡器的作用和特点，它具备哪三大功能?实现原理又是怎样的?

1. 多链路负载均衡

关键业务都需要安排和配置多条 ISP(网络服务供应商)接入链路来保证网络服务的可靠性。

如果某个 ISP 停止服务或者服务异常了，那么可以利用另一个 ISP 替代服务，提高了网络的可用性。

不同的 ISP 有不同自治域，因此需要考虑两种情况：

- INBOUND
- OUTBOUND

INBOUND，来自网络的请求信息。F5 分别绑定两个 ISP 服务商的公网地址，解析来自两个 ISP 服务商的 DNS 解析请求。

F5 可以根据服务器状况和响应情况对 DNS 进行发送，也可以通过多条链路分别建立 DNS 连接。

OUTBOUND，返回给请求者的应答信息。F5 可以将流量分配到不同的网络接口，并做源地址的 NAT(网络地址转换)，即通过 IP 地址转换为源请求地址。

也可以用接口地址自动映射，保证数据包返回时能够被源头正确接收。

![F5](http://p1.pstatp.com/large/pgc-image/7774acc95ea44bf49587c7271fc7bb13)

多路负载的方式增强了网络接入层的可靠性

2. 防火墙负载均衡

针对大量网络请求的情况，单一防火墙的能力就有限了，而且防火墙本身要求数据同进同出，为了解决多防火墙负载均衡的问题，F5 提出了防火墙负载均衡的“防火墙三明治"方案。

防火墙会对用户会话的双向数据流进行监控，从而确定数据的合法性。如果采取多台防火墙进行负载均衡，有可能会造成同一个用户会话的双向数据在多台防火墙上都进行处理。

而单个防火墙上看不到完成用户会话的信息，就会认为数据非法因此抛弃数据。

所以在每个防火墙的两端要架设四层交换机，可以在作流量分发的同时，维持用户会话的完整性，使同一用户的会话由一个防火墙来处理。而这种场景就需要 F5 负载均衡器协助才能完成转发。

有趣的是，F5 协调上述方案的配置和实现后，会把“交换机”，“防火墙”，“交换机”夹在了一起好像三明治一样。

![防火墙三明治](http://p3.pstatp.com/large/pgc-image/74c5a164d8a94df99d60093e2c100a88)

防火墙“三明治”

3. 服务器负载均衡

在硬件负载均衡器挂接多个应用服务器时，需要为这些服务做负载均衡，根据规则，让请求发送到服务器上去：

- 对于服务器的负载均衡的前提是，服务器都提供同样的服务，也就是同样的业务同时部署在多个服务器上。
- 对于应用服务器可以在 F5 上配置并且实现负载均衡，F5 可以检查服务器的健康状态，如果发现故障，将其从负载均衡组中移除。
- F5 对于外网而言有一个真实的 IP，对于内网的每个服务器都生成一个虚拟 IP，进行负载均衡和管理工作。因此,它能够为大量的基于 TCP/IP 的网络应用提供服务器负载均衡服务。
- 根据服务类型不同定义不同的服务器群组。
- 根据不同服务端口将流量导向对应的服务器。甚至可以对 VIP 用户的请求进行特殊的处理，把这类请求导入到高性能的服务器使 VIP 客户得到最好的服务响应。
根据用户访问内容的不同将流量导向指定服务器。

### 优缺点总结

聊完了硬件负载均衡器的特点和功能以后，让我们来总结一下它的优缺点：

- 优点：直接连接交换机，处理网络请求能力强，与系统无关，负载性能强。可以应用于大量设施，适应大访问量、使用简单。
- 缺点：成本高，配置冗余。即使网络请求分发到服务器集群，负载均衡设施却是单点配置;无法有效掌握服务器及应使用状态。

## 软件负载均衡

说完硬件负载均衡，再来谈谈软件负载均衡。软件负载均衡是指在一台或多台服务器的操作系统上安装一个或多个软件来实现负载均衡。

它的优点是基于特定环境，配置简单，使用灵活，成本低廉，可以满足一般的负载均衡需求。

代理层通常起到承上启下的作用，上连“接入层”，下接应用服务器(上游服务器)，可以做反向代理，缓存，数据验证，限流。本文会一一为各位介绍。

目前市面上比较流行的软件负载均衡有 LVS，HAProxy，Ngnix。由于篇幅有限我们通过应用广泛的 Nginx 为切入点，给大家讲解，之后会把上面三类软件进行一个对比。

### 功能描述和原理分析

对于程序员来说，接触最多的就是软件负载均衡。不仅要知道如何使用，同时也要了解背后的原理，下面列举了其最常用到的 4 大功能。

1. 反向代理与负载均衡

第一个功能是反向代理与负载均衡，如下图：

![反向代理和负载均衡](http://p1.pstatp.com/large/pgc-image/a4f769d2b3fe4dbab4d0794eec34e9b2)


客户端是如何把请求发送到应用服务器的

客户端把请求发送到应用服务器有如下几个步骤：

- 客户端请求 URL 给 DNS。
- DNS 将 URL 转化成对应的 IP。
- 通过 IP 找到服务器。
- 服务器接受到请求的报文，转交给接入层处理，接入层由于采用了硬件负载均衡器，所以能够扛住大数据量。
- 接入层把报文再次转交给代理层(并发 5W)，代理层的 Nginx 收到报文再根据反向代理的策略发送给上游服务器(应用服务器)。

负载均衡的算法/策略

实际上负载均衡的算法是很多的，这里以 Nginx 为例，介绍五种算法：

- Round-Robin：轮询算法，默认算法。对上游的服务器进行挨个轮询，这个算法是可以配合 Weight(权重)来实现的。
- Weight：权重算法，给应用服务器设置 Weight 的值。Weight 默认值为 1，Weight 参数越大被访问的几率越大。可以根据服务器的配置和资源情况配置 Weight 值，让资源情况乐观的服务器承担更多的访问量。
- IP-Hash：这个算法可以根据用户 IP 进行负载均衡，同一 IP 的用户端请求报文是会被同一台上游服务器响应的。也就是让同一客户端的回话(Session)保持一致。
- Least_conn：把请求转发给连接数较少的后端服务器。轮询算法是把请求平均的转发给各个后端，使它们的负载大致相同;但是，有些请求占用的时间很长，会导致其所在的后端负载较高。这种情况下，Least_conn 这种方式就可以达到更好的负载均衡效果。
- Hash Key：这个算法是对 Hash 算法的补充，主要是考虑当出现上游服务器增加/删除的情况，请求无法正确的被同一服务器处理。

所以对每个请求都设置 Hash Key，这样就算服务器发生了变化，Key 的值没有变，也可以找到对应的服务器。

2. 动态负载均衡

一般上游服务器都采用微服务的架构，那么负载均衡会把数据报发给哪个服务呢?如果服务出现了问题如何通知负载均衡器呢?有新的服务注册怎么办呢?

![动态负载均衡](http://p1.pstatp.com/large/pgc-image/ee2eb637697541ffad3c623972f70b3b)


动态负载均衡流程

微服务首先会注册到“服务注册发现”中心(Consul，Eureka)。注册中心包含微服务的信息，Nginx 会定期从这里拉取服务信息(Lua)。

获取微服务信息以后，Nginx 收到数据报的时候，就可以从注册中心获取的服务地址，把信息传递给服务了。

3. 限流

限流的工作可以在接入层用硬件负载均衡器来完成，也可以在代理层来完成。

限流实际上就是限制流入请求的数量，其算法不少，有令牌桶算法，漏桶算法，连接数限制等等。这里我们就介绍三个常用的。一般通过 Nignx+Lua 来实现。

连接数限流：通过 ngx_http_limit_conn_module 模块实现。设置最大的连接数以及共享内存的区域大小，请求的时候判断是否超过了最大连接数。

如果超过最大连接数就被限流，否则针对连接数就 +1，请求结束以后会将连接数 -1。

漏桶算法：通过 ngx_http_limit_req_module 模块实现。一个固定容量的桶，数据报按照固定的速度流出。

数据报可以按照任意的速度流入桶中，如果数据报的容量超过了桶的容量，再流入的数据报将会被丢弃。

按照这个规则，需要设置限流的区域以及桶的容量，以及是否延迟。

![漏桶](http://p3.pstatp.com/large/pgc-image/36ef8a8f431a4a10a08d2e82f46c50e0)


漏桶策略

令牌桶算法，桶的大小是固定的，以固定的速度往桶里丢令牌。桶满了后，后面添加的令牌无法添加。

数据报到来时从桶中取令牌，如果桶中有令牌，凭借令牌处理请求，处理完毕令牌销毁;数据报到来时发现桶中没令牌，该请求将被拒绝。

请求在发往令牌桶之前需要经过过滤/分类器，可以对报文进行分类，例如：某类报文可以直接发往应用服务器，某类报文需要经过令牌桶获取令牌以后才能发。

又例如：VIP 就可以直接把请求发往服务器，用不着经过令牌桶。

![漏桶](http://p1.pstatp.com/large/pgc-image/32c70f78a2724cb7b217984ba415f913)


令牌桶示意图

4. 缓存

![缓存](http://p3.pstatp.com/large/pgc-image/96bb25fd57604119ab317c40088e06ea)

Nginx 本地缓存机制

接入层发送请求，如果能够在 Nginx 本地缓存命中，直接返回缓存数据，如果没有命中回源到应用服务器。

缓存更新服务器定时更新 Nginx 本地缓存信息。这些需要考虑数据的一致性，何时更新以及何时失效等情况。

Nginx 缓存可以大大提高请求响应时间，可以把不经常更改的信息，例如：用户信息，提前放入缓存中，每次请求就不用再去请求应用服务器了。一旦用户信息更新，可以按照一定时钟频率写入缓存中。

另外，一般 HTTPHEAD 中都带有一些信息更新的信息。Nginx 也可以通过 expires，etag，if-modified-since 来实现浏览器缓存的控制。

其他的几个功能如下：

- 客户端超时重试
- DNS 超时重试
- 代理超时重试
- 失败重试
- 心跳检测
- 配置上有服务器

## 流行的软件负载均衡器

目前比较流行的有 LVS，Nginx 和 HAProxy，逐个看看他们的特点。

1. LVS

LVS(Linux Virtual Server) 是使用 Linux 内核集群实现的一个高性能、高可用的负载均衡服务器，它具有很好的可伸缩性(Scalability)、可靠性(Reliability)和可管理性(Manageability)。

LVS 特点是：

- 仅作分发之用，即把请求直接分发给应用服务器，因此没有流量的产生，对资源的消耗低。
- 配置简单，能够配置的项目少。
- 工作在第四层(传输层)，支持 TCP/UDP，对应用的支持广泛。

2. HAProxy

HAProxy 实现了一种事件驱动，单一进程模型，此模型支持非常大的并发连接数。

多进程或多线程模型受内存限制 、系统调度器限制以及无处不在的锁限制，很少能处理数千并发连接。

HAProxy 特点是：

- 支持虚拟主机。
- 支持 Session 保持，Cookie 引导。
- 通过指定的 URL 来检测应用服务器的状态。
- 支持 TCP/HTTP 协议转发。

3. Nginx

Nginx 是一款轻量级的 Web 服务器/反向代理服务器及电子邮件(IMAP/POP3)代理服务器，并在一个 BSD-like 协议下发行。

Nginx 特点是：

- 工作在网络的 4/7 层，对 HTTP 应用做负载均衡策略，如：域名、目录结构。
- 对网络的稳定性依赖小，可以区分内网和外网的访问。
- 安装和配置相对简单。
- 能承受很高负载且稳定，处理的流量依赖于按照 Nginx 服务器的配置。
- 可以检测服务器的问题，可以对服务器返回的信息进行处理和过滤，避免让无法工作的服务器响应请求。
- 对请求可以进行异步处理。
- 支持 HTTP、HTTPS 和 EMAIL。

## 网络负载均衡的技术选型

既然上面对软/硬件负载均衡有了总体的了解，那么按照“技术服务业务”的原则，在业务发展的不同阶段，如何使用这两类负载均衡技术呢?

1. 发展阶段

企业业务从 0 到 1，从无到有，数据量和访问量都不大。Nginx 或 HAProxy 进行单点的负载均衡就已经足够了。

这阶段刚刚采用多台应用服务器、数据库，需要一定的负载均衡做支撑。由于业务量不大，所以没有专业的维护团队来维护，也没有大规模的网站部署的需求。

因此 Nginx 或 HAproxy 是第一选择，因为其上手快， 配置容易，在七层之上利用 HTTP 协议就能满足要求了。

2. 扩张阶段

随着业务量增大，用户访问和交易量也在逐步增加，这时单点的 Nginx 或 HAProxy 已经无法满足之前的需求了。

使用 LVS 或者硬件负载均衡(F5/Array)就是架构师需要考虑的问题了，Nginx 此时就作为 LVS 或者硬件负载均衡(F5/Array)的节点来处理。

软件负载均衡+硬件负载均衡的架构配置在这个阶段就需要考虑了，也是对架构设计者的挑战。

3. 成熟阶段

随着公司业务扩张到达顶峰，之前的网络服务已经升级成主流服务产品，需要考虑在开源产品上进行业务定制，所以开源的 LVS，已经成为首选。其在深度定制之后依旧会和硬件负载均衡器配合完成业务服务。

## 总结

今天内容比较多，总结下来，三句话：

- 硬件和软件负载均衡，分别工作在“接入层”和“代理层”。
- 一个专注于网络，负责多链路，防火墙以及服务器的负载均衡，例如：F5 BIG-IP。
- 另一个偏向于业务，主要功能是反向代理，动态代理，缓存，限流，例如：LVS，Nginx，HAProxy。

# 延伸阅读

## 负载均衡的实现方式

1. http重定向协议实现负载均衡

根据用户的http请求计算出一个真实的web服务器地址，并将该web服务器地址写入http重定向响应中返回给浏览器，由浏览器重新进行访问。该方式比较简单，但性能较差，

2. 【协议层】dns域名解析负载均衡

在DNS服务器上配置多个域名对应IP的记录。该方式直接将负载均衡的工作交给了DNS，为网站管理维护省掉了很多麻烦，访问速度快，有效改善性能。

一般用来实现地理级别的均衡。例如，北方的用户访问北京的机房，南方的用户访问深圳的机房。

![DNS负载均衡](http://p3.pstatp.com/large/pgc-image/e46ac9a5079a4047be4c141b1b34c1fa)

3. 【协议层】反向代理负载均衡 ☆☆☆

反向代理服务器在提供负载均衡功能的同时，管理着一组web服务器，根据负载均衡算法将请求的浏览器访问转发到不同的web服务器处理，处理结果经过反向服务器返回给浏览器。该方式部署简单，但是web 服务器地址不能直接暴露在外，不需要使用外部IP地址，而反向代理服务作为沟通桥梁就需要配置双网卡、外部内部两套IP地址。

4. 【网络层】IP负载均衡

在网络层通过修改目标地址进行负载均衡。该方式在响应请求时速度较反向服务器负载均衡要快，但是，当请求数据较大(大型视频或文件)时，速度反应就会变慢。

5. 【链路层】数据链路层负载均衡

在数据链路层修改Mac地址进行负载均衡，负载均衡服务器的IP和它所管理的web 服务群的虚拟IP一致。它不需要负载均衡服务器进行地址的转换，但是对负载均衡服务器的网卡带宽要求较高。

6. F5

F5的全称是F5-BIG-IP-GTM，是最流行的硬件负载均衡设备，其并发能力达到百万级。该方式能够实现多链路的负载均衡和冗余，可以接入多条ISP链路，在链路之间实现负载均衡和高可用。

## 项目拓展方法论
看网讲网实际上包含了从兴趣激发，看网，到讲网三个阶段，主要参与人员为客户经理，产品经理，IT服务，看网专家。 帮助客户做现网体检，评估和规划，最好是针对已经突破的客户，具备一定客户关系优势。

| 阶段 | 关键活动 | 主要任务 | 目的 |
| --- | --- | --- | --- |
| 兴趣激发 | CXO，签署授权书 | 客户同意开展看网讲网 | - |
| 看网 | kickoff开工会，信心收集与调研，分析评估 | 4看，看架构，看过保，看性能，看规划 | 深入了解客户需求 |
| 讲网 | 方案设计，方案汇报 | 4讲：讲演进，讲TCO，讲体验，讲整合 | 解决方案营销 |

看网讲网报告通常要包含：
- 概览，现网问题（现网拓扑和关键发现，目标架构和拓扑），TO-BE方案和商业收益
- 关键信息KM的传递，注重商业价值，降TCO，提升业务体验；
- 关键发现要做到4维度展示（架构，过保，性能，容量）

看网讲网过程中客户的常见问题：
- 看网讲网对客户有什么好处？
- 看网讲网要收集那些信息？
  - 1） CMDB（基础信息，如型号/容量/过保，做过保和TCO分析等）
  - 2） 应用/存储/灾备的配置，性能日志，做业务性能，业务连续性等深入分析
- 收集信息对向往是否有影响
  - 1） 不会在被收集对象安装任何插件，是直接调用被收集对象提供的稳定可靠的命令或者接口来获取
  - 2） 收集前和收集过程中会对呗收集对象运行状态，负载进行检测，如果检测到设备异常或负载高，则停止收集
  - 3）收集内容和收集采用的命令或接口有user guide说明，收集过程中又详细的日志，记录收集操作和收集内容
- 需要客户如何配合？
  - 1）客户授权SmartIDC收集和分析信息
  - 2）客户侧运维，dBA相关领域参与收集
  - 3）客户提供一台运行SmartIDC收集工具的客户端，一台分析服务器（数据不出数据中心的情况下使用）
- 客户侧收集信息不能出数据中心，如何解决？
  - SmartIDC支持在客户中心部署进行看网讲网分析

总结：
- 看网讲网是加速业务进核心、上量的有效途径
- 客户经理在看网讲网中的关键作用
  - 推动客户同意看网讲网
    - 选定目标客户：设备老旧（常见存储，服务器，交换机，软件版本老旧，孤岛等），OPEX高，业务体验差，数据中心整合
    - 传递商业价值，分享成功案例
  - 看网报告KM高层传递
    - 商业价值：聚焦TCO节省和业务体验提升
    - 关键发现：从架构、过保、性能与容量等4个维度进行评估
- 客户经理参与并推动看网讲网在客户全面铺开

## 负载均衡典型架构

3种常见的负载均衡机制：DNS负载均衡、硬件负载均衡、软件负载均衡，每种方式都有一些优缺点，但并不意味着在实际应用中只能基于它们的优缺点进行非此即彼的选择，反而是基于它们的优缺点进行组合使用。具体来说，组合的基本原则为：

- DNS负载均衡用于实现地理级别的负载均衡；
- 硬件负载均衡用于实现集群级别的负载均衡；
- 软件负载均衡用于实现机器级别的负载均衡。

以一个假想的实例来说明一下这种组合方式，如下图所示。

![典型架构](http://p1.pstatp.com/large/pgc-image/bfe1c4cb8c0849dead129d1b6ef456e5)

整个系统的负载均衡分为三层。

- 地理级别负载均衡：www.xxx.com部署在北京、广州、上海三个机房，当用户访问时，DNS会根据用户的地理位置来决定返回哪个机房的IP，图中返回了广州机房的IP地址，这样用户就访问到广州机房了。
- 集群级别负载均衡：广州机房的负载均衡用的是F5设备，F5收到用户请求后，进行集群级别的负载均衡，将用户请求发给3个本地集群中的一个，我们假设F5将用户请求发给了“广州集群2”。
- 机器级别的负载均衡：广州集群2的负载均衡用的是Nginx，Nginx收到用户请求后，将用户请求发送给集群里面的某台服务器，服务器处理用户的业务请求并返回业务响应。

# 阿里自研负载均衡搞定双11

https://www.toutiao.com/a6580144988833710596/

# 如何利用Alluxio实现数据湖方案

https://cloud.tencent.com/developer/news/339999

# 价值链理论

迈克尔.波特的价值链理论，企业的价值分为两个维度，一个是以业务为主线的主价值链，一个是支撑业务的辅助价值链。现有的大部分中大型企业基本上是以价值链维度来划分组织及流程设计，而且大都采用科层式的组织架构，与此相对应的组织划分就是管理职能部门及业务部门。

![价值链理论](http://p1.pstatp.com/large/dfic-imagehandler/8bd88f24-060f-4feb-8ba8-bd2113063e7a)

以家电企业为例，理想的情况是从接到客户个性化定制订单（C2M定制）开始驱动一系列流程，业务主线是从协同设计到排产、到供应链管理，到生产执行再到物流运输，直到把商品交付给客户，管理主线是采购合同审批、财务结算、绩效管理等等。理想状态下的人与人之间的协同见下图：

![价值链理论](http://p3.pstatp.com/large/dfic-imagehandler/32147298-e183-45ff-a6cb-48ffdc38134a)
